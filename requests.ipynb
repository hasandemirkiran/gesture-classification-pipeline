{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training successful!\n",
      "Mean Accuracy:  0.8995535714285714\n"
     ]
    }
   ],
   "source": [
    "def training_get_request(version):\n",
    "    # Define the API endpoint URL\n",
    "    training_url = f\"http://localhost:8000/train/?version={version}\"\n",
    "\n",
    "    # response = requests.get(url, json={\"data\": data})\n",
    "    response = requests.get(training_url)\n",
    "\n",
    "    # Check the response status code\n",
    "    if response.status_code == 200:\n",
    "        # Model training successful\n",
    "        print(\"Model training successful!\")\n",
    "        print(\"Mean Accuracy: \", response.json()[\"evaluation_metrics\"][\"accuracy\"])\n",
    "    else:\n",
    "        # Model training failed\n",
    "        print(f\"Model training failed: {response.status_code} - {response.text}\")\n",
    "\n",
    "\n",
    "version = \"v3\"\n",
    "training_get_request(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: {'predictions': [1, 4, 2, 2, 0, 1, 6, 3, 2, 0]}\n"
     ]
    }
   ],
   "source": [
    "def perfom_inference(test_data, version):\n",
    "    predict_url = \"http://localhost:8000/predict/\"\n",
    "\n",
    "    # Define the payload with the test data\n",
    "    payload = {\"prediction_data\": test_data.to_dict(), \"version\": version}\n",
    "\n",
    "    # Send a POST request to the predict endpoint\n",
    "    response = requests.post(predict_url, json=payload)\n",
    "\n",
    "    # Check the response status code and content\n",
    "    if response.status_code == 200:\n",
    "        print(\"Predictions:\", response.json())\n",
    "    else:\n",
    "        print(\"Failed to get predictions. Status code:\", response.status_code)\n",
    "\n",
    "\n",
    "test_data = pd.read_pickle(\"test_data/X_test_1.pkl\")\n",
    "perfom_inference(test_data, \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92233   0.96939   0.94527        98\n",
      "           1    0.97345   0.97345   0.97345       113\n",
      "           2    0.84800   0.92982   0.88703       114\n",
      "           3    0.92661   0.84874   0.88596       119\n",
      "           4    0.84545   0.87736   0.86111       106\n",
      "           5    0.87850   0.83929   0.85845       112\n",
      "           6    0.90351   0.88793   0.89565       116\n",
      "           7    0.90435   0.88136   0.89270       118\n",
      "\n",
      "    accuracy                        0.89955       896\n",
      "   macro avg    0.90028   0.90092   0.89995       896\n",
      "weighted avg    0.90051   0.89955   0.89938       896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_modelparams_report(version):\n",
    "    evaluation_report_url = f\"http://localhost:8000/get_modelparams_and_report/?version={version}\"\n",
    "\n",
    "    # Send a POST request to the predict endpoint\n",
    "    response = requests.get(evaluation_report_url)\n",
    "\n",
    "    # Check the response status code\n",
    "    if response.status_code == 200:\n",
    "        # Get evaluation report succesfull\n",
    "        print(response.json()[\"report\"])\n",
    "    else:\n",
    "        # Get evaluation report failed\n",
    "        print(f\"Getting Evaluation Report failed: {response.status_code} - {response.text}\")\n",
    "\n",
    "\n",
    "version = \"v2\"\n",
    "get_modelparams_report(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version v3 deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "def delete_model_version(version):\n",
    "    delete_model_url = f\"http://localhost:8000/delete_model_version?version={version}\"\n",
    "\n",
    "    # Send a DELETE request to the endpoint\n",
    "    response = requests.delete(delete_model_url)\n",
    "\n",
    "    # Check the response status code\n",
    "    if response.status_code == 200:\n",
    "        # Model version deletion successful\n",
    "        print(f\"Model version {version} deleted successfully.\")\n",
    "    else:\n",
    "        # Model version deletion failed\n",
    "        print(f\"Failed to delete model version {version}: {response.status_code} - {response.text}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "version = \"v3\"\n",
    "delete_model_version(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extended and model retrained successfully.\n",
      "Mean Accuracy:  0.9006696428571429\n"
     ]
    }
   ],
   "source": [
    "def extend_dataset(data_path):\n",
    "    extend_dataset_url = \"http://localhost:8000/extend_dataset/\"\n",
    "\n",
    "    # Set up the query parameter\n",
    "    params = {\"data_path\": data_path}\n",
    "\n",
    "    # Send a POST request to the endpoint with query parameter\n",
    "    response = requests.post(extend_dataset_url, params=params)\n",
    "\n",
    "    # Check the response status code\n",
    "    if response.status_code == 200:\n",
    "        # Dataset extension and model retraining successful\n",
    "        print(\"Dataset extended and model retrained successfully.\")\n",
    "        print(\"Mean Accuracy: \", response.json()[\"evaluation_metrics\"][\"accuracy\"])\n",
    "    else:\n",
    "        # Dataset extension and model retraining failed\n",
    "        print(f\"Failed to extend dataset and retrain model: {response.status_code} - {response.text}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "data_path = \"extend_data/extend_1.pkl\"\n",
    "extend_dataset(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celonis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
